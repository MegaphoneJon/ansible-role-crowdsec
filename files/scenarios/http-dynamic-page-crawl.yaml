type: leaky
name: MegaphoneJon/http-dynamic-page-crawl
description: >
  Detect headless scrapers requesting multiple dynamic pages without fetching static assets.
distinct: evt.Meta.http_path
# Add "evt.Parsed.static_ressource == "false" &&" to the top of the filter when trying to ID which lines triggered the scenario.
filter: |
  evt.Meta.service == "http" &&
  evt.Parsed.verb == "GET" &&
  evt.Parsed.file_name != "admin-ajax.php" &&
  evt.Parsed.file_name != "post.php" &&
  evt.Parsed.request not startsWith "/wp-admin/admin.php" &&
  evt.Parsed.request not startsWith "/wp-json" &&
  evt.Parsed.file_dir != "/civicrm/report/instance/" &&
  evt.Parsed.file_dir != "/civicrm/mosaico/" &&
  evt.Parsed.file_dir != "/civicrm/asset/builder/" &&
  evt.Parsed.file_dir not startsWith "/civicrm/ajax/" &&
  evt.Parsed.request not startsWith  "/civicrm/file" &&
  evt.Parsed.file_dir not startsWith "/civicrm/contact/" &&
  evt.Parsed.file_name not startsWith "/.well-known/acme-challenge" &&
  evt.Parsed.http_args not endsWith "preview=true"
groupby: "evt.Meta.source_ip"
blackhole: 5m
capacity: 5
leakspeed: 7s
# Instead of filtering these out, we add them to the bucket so we can destroy the bucket when they're requested.
# This allows us to "forgive" page loads for users downloading static resources.
cancel_on: evt.Parsed.static_ressource == "true"
labels:
  service: http
  type: headless-crawl
  remediation: true
